{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6e6882-e004-4a33-9632-bdd902c0d45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import operator\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c95f715-b98a-485c-9e75-f59de25753fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_vision = create_engine(f'mysql+pymysql://fnbrasil:{password}@localhost:3307/vision_db', pool_recycle=3600)\n",
    "engine_fnbrdb = create_engine(f'mysql+pymysql://fnbrasil:{password}@localhost:3307/fnbr_db', pool_recycle=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a1c829-6e8c-44ad-8607-32aa67ff2ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_names = pd.read_sql('''\n",
    "    select frame.idFrame, entry.name\n",
    "    from frame\n",
    "    join entry on entry.entry = frame.entry\n",
    "    where entry.idLanguage = 2;''', engine_fnbrdb)\n",
    "\n",
    "fe_names = pd.read_sql('''\n",
    "    select frameelement.idFrameElement , entry.name\n",
    "    from frameelement \n",
    "    join entry on entry.entry = frameelement.entry\n",
    "    where entry.idLanguage = 2;''', engine_fnbrdb)\n",
    "\n",
    "frame_names = { r[\"idFrame\"]:r[\"name\"] for _, r in frame_names.iterrows() } \n",
    "fe_names = { r[\"idFrameElement\"]:r[\"name\"] for _, r in fe_names.iterrows() } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcbe216f-18ce-4bfc-8ce7-841eedf37eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_txt(file_path, series):\n",
    "    \"\"\"\n",
    "    Write a pd.Series into a .txt file.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): The path to the .txt file.\n",
    "    series: The pd.Series being stored.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"w\") as fp:\n",
    "        for sent in series:\n",
    "            fp.write(sent + \"\\n\")\n",
    "\n",
    "\n",
    "def read_jsonl(file_path):\n",
    "    \"\"\"\n",
    "    Read a JSONL file and return a list of dictionaries.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): The path to the JSONL file.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries representing JSON objects.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_name(id, type=None):\n",
    "    \"\"\"\n",
    "    Gets the name of a FrameNet entity. \n",
    "\n",
    "    Args:\n",
    "    id: The integer id of the entity or a string with the type and the id.\n",
    "    type (str): The type of entity. Must be specified if id is int.\n",
    "    \"\"\"\n",
    "    if isinstance(id, str) and type is None:\n",
    "        matches = re.match(r\"(\\w+)_(\\d+)\", id)\n",
    "        if matches is None:\n",
    "            print(id)\n",
    "        type = matches.group(1)\n",
    "        id = int(matches.group(2))\n",
    "\n",
    "    if type == \"frm\":\n",
    "        return frame_names[id]\n",
    "    elif type == \"fe\":\n",
    "        return fe_names[id]\n",
    "    else:\n",
    "        raise \"Failed to infer entity type\"\n",
    "\n",
    "\n",
    "def lome_to_release(annotation): \n",
    "    \"\"\"\n",
    "    Converts a LOME output tree to the release format used in Framed30k.\n",
    "\n",
    "    Args:\n",
    "    annotation (dict): The dict representing the output tree of the instance.\n",
    "    \"\"\"\n",
    "    return [{\n",
    "        \"id\": get_name(frame[\"label\"]),\n",
    "        \"span\": frame[\"span\"],\n",
    "        \"frameElements\": [{\n",
    "            \"id\": get_name(fe[\"label\"]),\n",
    "            \"span\": fe[\"span\"]\n",
    "        } for fe in frame[\"children\"] if fe[\"label\"] != \"@@PADDING@@\" ]\n",
    "    } for frame in annotation[\"children\"]]\n",
    "\n",
    "\n",
    "def to_multi30k_task1(df, set):\n",
    "    \"\"\"\n",
    "    Stores subsets of the dataframe sets according to the Multi30k's task1 splits.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the release data.\n",
    "    set (str): The subset being stored. Can be 'train', 'val', 'test_2016_flickr' or 'test_2016_images'.\n",
    "    \"\"\"\n",
    "    split_path = os.path.join(\"multi30k-dataset\", \"data\", \"task1\", \"image_splits\", f\"{set}.txt\")\n",
    "    output_base = os.path.join(\"release\", \"multi30k\", \"task1\")\n",
    "\n",
    "    with open(split_path) as fp:\n",
    "        images = [line.rstrip('\\n') for line in fp]\n",
    "\n",
    "    merged = pd.DataFrame(pd.Series(images, name=\"imageFile\")).reset_index().merge(df)\n",
    "    merged = merged.sort_values(\"index\")\n",
    "\n",
    "    # save raw\n",
    "    with open(os.path.join(output_base, \"raw\", f\"{set}.pt\"), \"w\") as fp:\n",
    "        for sent in merged[\"sentence\"]:\n",
    "            fp.write(sent + \"\\n\")\n",
    "\n",
    "    # save tok\n",
    "    with open(os.path.join(output_base, \"tok\", f\"{set}.lc.norm.tok.pt\"), \"w\") as fp:\n",
    "        for tokens in merged[\"tokens\"]:\n",
    "            fp.write(' '.join(tokens).lower() + \"\\n\")\n",
    "\n",
    "\n",
    "def to_multi30k_task2(df, set):\n",
    "    \"\"\"\n",
    "    Stores subsets of the dataframe sets according to the Multi30k's task2 splits.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the release data.\n",
    "    set (str): The subset being stored. Can be 'train', 'val', 'test_2016'.\n",
    "    \"\"\"\n",
    "    split_path = os.path.join(\"multi30k-dataset\", \"data\", \"task2\", \"image_splits\", f\"{set}_images.txt\")\n",
    "    output_base = os.path.join(\"release\", \"multi30k\", \"task2\")\n",
    "\n",
    "    with open(split_path) as fp:\n",
    "        images = [line.rstrip('\\n') for line in fp]\n",
    "\n",
    "    merged = pd.DataFrame(pd.Series(images, name=\"imageFile\")).reset_index().merge(df)\n",
    "    merged = merged.sort_values(\"index\")\n",
    "\n",
    "    # save raw\n",
    "    for i in range(1, 6):\n",
    "        subset = merged[merged[\"sentenceNumber\"] == i]\n",
    "        \n",
    "        assert len(subset) == len(images)\n",
    "        \n",
    "        with open(os.path.join(output_base, \"raw\", f\"{set}.{i}.pt\"), \"w\") as fp:\n",
    "            for sent in subset[\"sentence\"]:\n",
    "                fp.write(sent + \"\\n\")\n",
    "\n",
    "    # save tok\n",
    "    for i in range(1, 6):\n",
    "        subset = merged[merged[\"sentenceNumber\"] == i]\n",
    "        \n",
    "        assert len(subset) == len(images)\n",
    "        \n",
    "        with open(os.path.join(output_base, \"tok\", f\"{set}.lc.norm.tok.{i}.pt\"), \"w\") as fp:\n",
    "            for tokens in subset[\"tokens\"]:\n",
    "                fp.write(' '.join(tokens).lower() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd88ef2-f8c9-4b78-84fa-ef1aeec7d731",
   "metadata": {},
   "source": [
    "## PTT sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d0799f-4c21-4783-9570-1ce01c4ec519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "ptt = pd.read_sql('''\n",
    "    select ptt.idAnnotation, image.imageFile, eno.sentenceNumber, ptt.sentence\n",
    "    from annotation ptt\n",
    "    join annotation eno on eno.idAnnotation = ptt.idRefAnnotation \n",
    "    join image on image.idImage = eno.idImage \n",
    "    where ptt.source = 'vision'\n",
    "    \tand exists (\n",
    "    \t\tselect 1\n",
    "    \t\tfrom annotation det\n",
    "    \t\twhere source in ('multi30k-german', 'multi30k-german-2k-sample')\n",
    "    \t\t\tand det.idRefAnnotation = ptt.idRefAnnotation \n",
    "    \t);''', engine_vision)\n",
    "\n",
    "ptt[\"sentenceNumber\"] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a056ab54-e530-4ee7-98d8-4d29f45f8256",
   "metadata": {},
   "source": [
    "Filter out any duplicates for any imageFile#sentenceNumber, preserve the longest.\n",
    "\n",
    "We expect exactly 31014 records after that operation (this number comes from Multi-Flickr30k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98dd972e-8b6c-44c2-820f-8f94cbfee223",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "for _, group in ptt.groupby([\"imageFile\", \"sentenceNumber\"])[\"sentence\"]:\n",
    "    idxs.append(group.str.len().idxmax())\n",
    "\n",
    "\n",
    "assert len(idxs) == 31014\n",
    "\n",
    "ptt = ptt.loc[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3e1db4-2d4a-4c40-9b4b-180dcbf5ad77",
   "metadata": {},
   "source": [
    "Write to text file to be consumed by LOME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f8fb846-07be-4ece-80af-f3673d4e8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_txt(\"data/ptt.txt\", ptt[\"sentence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43959d34-055d-4d48-a7bb-1bbbfd1f4887",
   "metadata": {},
   "source": [
    "Build release file for annotation and in raw formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f64eacb-01e6-4e43-bd19-0b07bb873ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by sorting\n",
    "ptt.sort_values([\"imageFile\", \"sentenceNumber\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d11845c5-d086-442a-a30b-b0fb5de5fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lome_output = read_jsonl(\"data/ptt.jsonl\")\n",
    "\n",
    "assert len(lome_output) == 31014\n",
    "\n",
    "ptt[\"tokens\"] = list(map(operator.itemgetter(\"tokens\"), lome_output))\n",
    "ptt[\"frames\"] = list(map(lome_to_release, map(operator.itemgetter(\"annotation\"), lome_output)))\n",
    "\n",
    "ptt.rename(columns={\n",
    "    \"idAnnotation\": \"sentenceId\",\n",
    "    \"imageFile\": \"flickr30kImageId\",\n",
    "    \"sentenceNumber\": \"flickr30kSentenceNumber\",\n",
    "}).to_json(\"release/framed30k/PTT.jsonl\", orient=\"records\", lines=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f7d96b5-8839-4c03-a1b4-43245b611cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame labels (PTT):  193143\n",
      "FE labels (PTT):  179829\n",
      "Total labels (PTT):  372972\n",
      "Avg p/ sent (PTT):  12.025923776359063\n"
     ]
    }
   ],
   "source": [
    "frm_ptt_labels = ptt[\"frames\"].map(len)\n",
    "fe_ptt_labels = ptt[\"frames\"].map(lambda frames: sum(len(frm[\"frameElements\"]) for frm in frames))\n",
    "\n",
    "print('Frame labels (PTT): ', frm_ptt_labels.sum())\n",
    "print('FE labels (PTT): ', fe_ptt_labels.sum())\n",
    "print('Total labels (PTT): ', (frm_ptt_labels + fe_ptt_labels).sum())\n",
    "print('Avg p/ sent (PTT): ', (frm_ptt_labels + fe_ptt_labels).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77a5e45f-91ee-4eaf-9258-799e1c9190e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_multi30k_task1(ptt, \"test_2016_flickr\")\n",
    "to_multi30k_task1(ptt, \"train\")\n",
    "to_multi30k_task1(ptt, \"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74b557a-d33e-46c7-9bb4-98be751f96e9",
   "metadata": {},
   "source": [
    "## PTO sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ab5a905-d6e7-47e9-84d9-68f999c1d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "pto = pd.read_sql('''\n",
    "    select pto.idAnnotation, image.imageFile, pto.sentence\n",
    "    from annotation pto\n",
    "    join image on image.idImage = pto.idImage \n",
    "    where pto.source = 'vision' and idRefAnnotation is null;''', engine_vision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c76cd14-dae6-4ce0-ab8b-aaae77c947cb",
   "metadata": {},
   "source": [
    "Select top-5 longest sentences for each image as the reference ones.\n",
    "\n",
    "Final dataset must have 158915 records (5 x 31783)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f84992a4-5af5-4268-9774-b2f297e6d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "for _, group in pto.groupby(\"imageFile\")[\"sentence\"]:\n",
    "    for i in group.str.len().nlargest(5).index:\n",
    "        idxs.append(i)\n",
    "\n",
    "assert len(idxs) == 158915\n",
    "\n",
    "pto = pto.loc[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1f376b-b4cc-48f7-9172-d37fe0266dda",
   "metadata": {},
   "source": [
    "Randomly assigns sentence numbers to new sentences (PTO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32803674-e8a7-4ca6-be09-78f589edbde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = list(range(1, 6))\n",
    "pto[\"sentenceNumber\"] = -1\n",
    "\n",
    "for _, group in pto.groupby(\"imageFile\"):\n",
    "    pto.loc[group.sample(frac=1, random_state=1234).index, \"sentenceNumber\"] = numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b1dfcd9-e2fc-429b-8a51-039fb34e7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by sorting\n",
    "pto.sort_values([\"imageFile\", \"sentenceNumber\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fae9d6-7deb-4c42-8f2e-8fbc6c4857f5",
   "metadata": {},
   "source": [
    "Write to text file to be consumed by LOME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41d2dced-2840-46ef-8015-f9010f33f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_txt(\"data/pto.txt\", pto[\"sentence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01e3c43-4e27-43db-9cbc-f090f6f2285d",
   "metadata": {},
   "source": [
    "Build release file for annotation and in raw formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8e83095-4bf5-4ebf-b665-02f5ea06ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "lome_output = read_jsonl(\"data/pto.jsonl\")\n",
    "\n",
    "assert len(lome_output) == 158915\n",
    "\n",
    "pto[\"tokens\"] = list(map(operator.itemgetter(\"tokens\"), lome_output))\n",
    "pto[\"frames\"] = list(map(lome_to_release, map(operator.itemgetter(\"annotation\"), lome_output)))\n",
    "\n",
    "pto.rename(columns={\n",
    "    \"idAnnotation\": \"sentenceId\",\n",
    "    \"imageFile\": \"flickr30kImageId\",\n",
    "    \"sentenceNumber\": \"flickr30kSentenceNumber\",\n",
    "}).to_json(\"release/framed30k/PTO.jsonl\", orient=\"records\", lines=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e044926-fd3a-4a70-bbeb-7e4ae9898e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame labels (PTO):  1106580\n",
      "FE labels (PTO):  1024456\n",
      "Total labels (PTO):  2131036\n",
      "Avg p/ sent (PTO):  13.409910958688608\n"
     ]
    }
   ],
   "source": [
    "frm_pto_labels = pto[\"frames\"].map(len)\n",
    "fe_pto_labels = pto[\"frames\"].map(lambda frames: sum(len(frm[\"frameElements\"]) for frm in frames))\n",
    "\n",
    "print('Frame labels (PTO): ', frm_pto_labels.sum())\n",
    "print('FE labels (PTO): ', fe_pto_labels.sum())\n",
    "print('Total labels (PTO): ', (frm_pto_labels + fe_pto_labels).sum())\n",
    "print('Avg p/ sent (PTO): ', (frm_pto_labels + fe_pto_labels).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6bd17c6-6ed2-4fe6-89c9-ce42afca75d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_multi30k_task2(pto, \"test_2016\")\n",
    "to_multi30k_task2(pto, \"train\")\n",
    "to_multi30k_task2(pto, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "122bc3f0-22fd-4b1c-bb9e-819589145b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_output = pto[\"imageFile\"] + \"#\" + pto[\"sentenceNumber\"].astype(str) + \"\\t\" + pto[\"sentence\"] + \"\\n\"\n",
    "\n",
    "with open(\"release/flickr30k/captions.txt\", \"w\") as fp:\n",
    "    for line in raw_output:\n",
    "        fp.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06244872-b1e1-488c-846b-d440361d8f1c",
   "metadata": {},
   "source": [
    "## ENO sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42564f82-cc87-4f8a-9973-29cd2ca98b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "eno = pd.read_sql('''\n",
    "    select eno.idAnnotation, image.imageFile, eno.sentenceNumber, eno.sentence\n",
    "    from annotation eno\n",
    "    join image on image.idImage = eno.idImage \n",
    "    where eno.source = 'flickr30k';''', engine_vision)\n",
    "\n",
    "eno[\"sentenceNumber\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92b4419f-b233-48e2-8fa5-9d04b261ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by sorting\n",
    "eno.sort_values([\"imageFile\", \"sentenceNumber\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf3c690-e074-4352-8af1-b88a21f0b454",
   "metadata": {},
   "source": [
    "Write to text file to be consumed by LOME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60d558c6-28f8-45de-b0ec-10a9effd7fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_txt(\"data/eno.txt\", eno[\"sentence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56f0de-239b-498e-9bfd-a481997ccd97",
   "metadata": {},
   "source": [
    "Build release file for annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a0559c4-2be5-42ad-ac80-78feb58425a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lome_output = read_jsonl(\"data/eno.jsonl\")\n",
    "\n",
    "assert len(lome_output) == 158915\n",
    "\n",
    "eno[\"tokens\"] = list(map(operator.itemgetter(\"tokens\"), lome_output))\n",
    "eno[\"frames\"] = list(map(lome_to_release, map(operator.itemgetter(\"annotation\"), lome_output)))\n",
    "\n",
    "eno.rename(columns={\n",
    "    \"idAnnotation\": \"sentenceId\",\n",
    "    \"imageFile\": \"flickr30kImageId\",\n",
    "    \"sentenceNumber\": \"flickr30kSentenceNumber\",\n",
    "}).drop(columns=[\"sentence\"]).to_json(\"release/framed30k/ENO.jsonl\", orient=\"records\", lines=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6e43a26-33cb-4bbf-86d8-a9f37df255ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame labels (ENO):  764860\n",
      "FE labels (ENO):  1308254\n",
      "Total labels (ENO):  2073114\n",
      "Avg p/ sent (ENO):  13.045426800490828\n"
     ]
    }
   ],
   "source": [
    "frm_eno_labels = eno[\"frames\"].map(len)\n",
    "fe_eno_labels = eno[\"frames\"].map(lambda frames: sum(len(frm[\"frameElements\"]) for frm in frames))\n",
    "\n",
    "print('Frame labels (ENO): ', frm_eno_labels.sum())\n",
    "print('FE labels (ENO): ', fe_eno_labels.sum())\n",
    "print('Total labels (ENO): ', (frm_eno_labels + fe_eno_labels).sum())\n",
    "print('Avg p/ sent (ENO): ', (frm_eno_labels + fe_eno_labels).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e040b21-203e-43c6-b4cf-fa2ada82d04e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## ENO reference sentences for translation\n",
    "enot = eno.merge(ptt[[\"imageFile\", \"sentenceNumber\"]], on=[\"imageFile\", \"sentenceNumber\"])\n",
    "\n",
    "write_to_txt(\"data/enot.txt\", enot[\"sentence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4172cc9b-9d67-4410-9734-7f78df875a7d",
   "metadata": {},
   "source": [
    "## Image annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4233929c-93be-4bea-8e91-31554ed44990",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = pd.read_sql('''\n",
    "    select\n",
    "    \tsentencemm.idSentenceMM,\n",
    "    \tcorpus.entry,\n",
    "    \timagemm.name as 'flickr30kImageId',\n",
    "    \tsentencemm.idFlickr30k+1 as 'flickr30kSentenceNumber',\n",
    "    \tfrme.name as 'frameName',\n",
    "    \tfee.name as 'feName',\n",
    "    \tomm.idFlickr30k as 'flickr30kEntitiesObjectId'\n",
    "    from corpus\n",
    "    join document on document.idCorpus = corpus.idCorpus\n",
    "    join documentmm on documentmm.idDocument = document.idDocument\n",
    "    join sentencemm on sentencemm.idDocumentMM = documentmm.idDocumentMM\n",
    "    join imagemm on imagemm.idImageMM = sentencemm.idImageMM\n",
    "    -- annotation part\n",
    "    join objectsentencemm osmm on osmm.idSentenceMM = sentencemm.idSentenceMM\n",
    "    join objectmm omm on omm.idObjectMM = osmm.idObjectMM \n",
    "    join frameelement fe on fe.idFrameElement = osmm.idFrameElement \n",
    "    join frame frm on frm.idFrame = fe.idFrame \n",
    "    join entry fee on fee.entry = fe.entry and fee.idLanguage = 2\n",
    "    join entry frme on frme.entry = frm.entry and frme.idLanguage = 2\n",
    "    where corpus.entry  in (\n",
    "    \t'crp_oficina_com_sentenca_1',\n",
    "    \t'crp_oficina_com_sentenca_2',\n",
    "    \t'crp_oficina_sem_sentenca_1',\n",
    "    \t'crp_oficina_sem_sentenca_2',\n",
    "    \t'crp_oficina_com_sentenca_3',\n",
    "    \t'crp_oficina_com_sentenca_4',\n",
    "    \t'crp_oficina_sem_sentenca_3',\n",
    "    \t'crp_oficina_sem_sentenca_4'\n",
    "    \t-- 'crp_nlperspectives-2k',\n",
    "    \t-- 'crp_flickr30k-1k-1',\n",
    "    \t-- 'crp_flickr30k-1k-2'\n",
    "    )\n",
    "    order by flickr30kImageId, flickr30kSentenceNumber;\n",
    "''', engine_fnbrdb)\n",
    "\n",
    "\n",
    "img[\"annotationCondition\"] = \"\"\n",
    "img.loc[img[\"entry\"].str.contains(\"flickr30k-1k\"), \"annotationCondition\"] = \"VWC\"\n",
    "img.loc[img[\"entry\"].str.contains(\"oficina_com_sentenca\"), \"annotationCondition\"] = \"VWC\"\n",
    "img.loc[img[\"entry\"].str.contains(\"crp_nlperspectives-2k\"), \"annotationCondition\"] = \"VNC\"\n",
    "img.loc[img[\"entry\"].str.contains(\"oficina_sem_sentenca\"), \"annotationCondition\"] = \"VNC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f364fdc2-eb73-40ae-ada9-b673eb3fc353",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_grouped = pd.DataFrame([\n",
    "    {\n",
    "        \"flickr30kImageId\": img_idx[1], \n",
    "        \"flickr30kSentenceNumber\": img_idx[2],\n",
    "        \"annotationCondition\": img_idx[0],\n",
    "        \"frames\": [\n",
    "            {\n",
    "                \"id\": frm_idx,\n",
    "                \"frameElements\": [\n",
    "                    { \"id\": r[\"feName\"], \"flickr30kEntitiesObjectId\": r[\"flickr30kEntitiesObjectId\"] }\n",
    "                    for _, r in frm_group.iterrows()\n",
    "                ]\n",
    "            }\n",
    "            for frm_idx, frm_group in img_group.groupby(\"frameName\")\n",
    "        ]\n",
    "    }\n",
    "    for img_idx, img_group in img.groupby([\"annotationCondition\", \"flickr30kImageId\", \"flickr30kSentenceNumber\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e816c233-6df5-4448-ac06-9352579b9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_grouped.to_json(\"release/framed30k/IMG.jsonl\", orient=\"records\", lines=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2aa9731a-e021-4d5c-a96d-b96fa6b42b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29920"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "187*40*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8c92b28-ce12-4199-814b-7a56ac5382ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flickr30kImageId</th>\n",
       "      <th>flickr30kSentenceNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10002456.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000268201.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000344755.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1000366164.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169535</th>\n",
       "      <td>969655512.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169539</th>\n",
       "      <td>96973080.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169544</th>\n",
       "      <td>96973080.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169548</th>\n",
       "      <td>969779007.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169553</th>\n",
       "      <td>96978713.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29831 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       flickr30kImageId  flickr30kSentenceNumber\n",
       "0        1000092795.jpg                        2\n",
       "4          10002456.jpg                        1\n",
       "10       1000268201.jpg                        4\n",
       "14       1000344755.jpg                        2\n",
       "22       1000366164.jpg                        4\n",
       "...                 ...                      ...\n",
       "169535    969655512.jpg                        4\n",
       "169539     96973080.jpg                        2\n",
       "169544     96973080.jpg                        5\n",
       "169548    969779007.jpg                        4\n",
       "169553     96978713.jpg                        3\n",
       "\n",
       "[29831 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[[\"flickr30kImageId\", \"flickr30kSentenceNumber\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea0cf90-c4bc-46d3-9977-4afb65d1ec0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "framed30k",
   "language": "python",
   "name": "framed30k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
